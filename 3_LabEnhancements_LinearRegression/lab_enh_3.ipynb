{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size=48>Lab Enchancement 3</font>**<br>\n",
    "\n",
    "By Lim Sir Yuean and Yap Jack\n",
    "\n",
    "Learning objectives:\n",
    "- Understand output determinant factors in Machine Learning.\n",
    "- Explore more mathematical applications in Machine Learning.\n",
    "\n",
    "References:\n",
    "- https://www.youtube.com/watch?v=DOXbE4hMF4Y\n",
    "- https://www.leewayhertz.com/what-are-neural-networks/#What-are-neural-networks\n",
    "- https://www.linkedin.com/pulse/understanding-gradient-descent-algorithm-its-role-linear-mhango-kjbvf/\n",
    "- https://medium.com/@dilip.voleti/maxima-vs-minima-and-global-vs-local-in-machine-learning-basic-concept-741e760e9f80\n",
    "- https://archive.is/0mAm0\n",
    "- https://www.investopedia.com/terms/l/least-squares-method.asp\n",
    "- https://www.youtube.com/watch?v=P8hT5nDai6A\n",
    "- https://suboptimal.wiki/explanation/mse/\n",
    "- https://statisticsbyjim.com/regression/mean-squared-error-mse/\n",
    "- https://www.youtube.com/watch?v=beIgcdf0YDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Foreword:</b>\n",
    "\n",
    "This lab will continue to delve deep into the mathematical inner workings of Machine Learning Algorithm.\n",
    "Afterwards, the lab will explore more on training sophisticated image recognition ML model.\n",
    "\n",
    "<b>Why?</b>\n",
    "- To gain a deeper and fundamental undestanding on the Machine Learning process .\n",
    "- To advance from basic ML models to applicable real-world ML models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\"This looks difficult, will I understand it?\"</b>\n",
    "\n",
    "With a solid understanding on Calculus principles and mathematical syntax operations, the concepts shown here will be a walk in the park.\n",
    "\n",
    "If you think your math is subpar, don't worry, this lab might just reinforce your current mathematical fluency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='cyan'>Training</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When people say \"<u>Training </u> a Model\", it basically means we are <u><b>minimizing a function</u></b>, which is f(x). \n",
    "\n",
    "Specifically, we are trying to minimize the ML model's <u><b>error</u></b> based on the trained data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What is error?</b>\n",
    "\n",
    "For example, we have a dataset of a few thousand people with their income data. We are trying to predict a person's income based on their current job, salary, and company type. The <b><u>error is the difference between the model's predicted person's income and the person's actual true income.</u></b> \n",
    "\n",
    "We could use a f(x) from calculus to present the error minimizing process. \n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"min_error_ml.jpg\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "The paratemer on the x-axis is what the model uses to make predictions. When we minimize the function, <b><u>we want to know what is the value on the x-axis that has the lowest error</b></u>. Then, we can use that value to make better predictions.\n",
    "\n",
    "How do we achieve this is explained in the Gradient Descent section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='lightgreen'>Linear Regression</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <b>Linear</b>: a line on a graph </center>\n",
    "<center> <b>Regression</b>: return to previous state </center>\n",
    "\n",
    "Linear regression is a concept from statistics. It is the simplest statistical regression technique used for predictive analysis, said to be the foundational work for the development of neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics, this can be represented as:\n",
    "\n",
    "<center><b>Y = w1â‹…x1 + w2â‹…x2 + w3â‹…x3 + b </b></center>\n",
    "\n",
    "Where:\n",
    "- w1, w2, w3, and \"b\" are parameters.\n",
    "\n",
    "- x1, x2, and x3 are data points.\n",
    "\n",
    "<b> What do they mean?</b>\n",
    "- \"Y\" is the target prediction.\n",
    "\n",
    "- \"x\" is a variable representing the data.\n",
    "\n",
    "- \"w\" stands for weight, it represents the <u>significance</u> of the data \"x\".\n",
    "\n",
    "- \"b\" stands for the base data value for predicting \"Y\".\n",
    "\n",
    "<b>Why is it so?</b>\n",
    "- Significance or weight represents how important the data is for a prediction. The higher the significance, the more influence the data will have in predicting the output.\n",
    "\n",
    "- Base data is a value range allowed for the output to be in. For example, when predicting a person's height, no one will have a height of zero. The base data is usually the mean of the dataset, but it is also learned and adjusted overtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When coding the linear regression equation, we will <b>transform the equation into a matrix form</b>. This method <b>speeds up runtime by computing all data at once </b> rather than iterating each data with a for-loop.  \n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"matrix_demo.jpg\" width=\"500\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we move on to the linear equation Formula. \n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"lin_1.jpg\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "\n",
    "Linear Regression is basically \"y = mx + b\", but with adding as many parameters as we want to predict an output.\n",
    "\n",
    "y = dependent variable (the outcome or response)\n",
    "\n",
    "x = independent variable (the predictor or feature)\n",
    "\n",
    "m = slope of the line (the coefficient that represents the rate of change of y with respect to x)\n",
    "\n",
    "b = the y-intercept (or the bias term)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression defines a linear function between the X and Y variables that best showcases the relationship between the two. It is represented by the slant line seen in the figure below, where the objective is to determine an optimal â€˜regression lineâ€™ that best fits all the individual data points.\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"BestFitLine.png\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "<b>How does Linear Regression use the equation?</b>\n",
    "\n",
    "1. Collect Data: We start by obtaining values for x and y.\n",
    "2. Plot the Data: We plot the values on a graph to visualize the relationship between x and y.\n",
    "3. Fit the Line: Linear regression uses the equation: y = mx + b to minimize the differences between the observed values and the values predicted by the line.\n",
    "\n",
    "<b>Why is This Important?</b>\n",
    "- The slope m shows the strength and direction of the relationship of x and y.\n",
    "- Linear Regression can use the equation: y = mx + b to predict y for any given x.\n",
    "\n",
    "To understand linear regression, we start by writing a linear equation that best fits the dataset shown below using the equation: y = mx + b\n",
    "low.\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"LSM table.jpg\" width=\"600\">\n",
    "</div>\n",
    "\n",
    " Firstly, we create a table with 4 columns: x, y, xy, xÂ²\n",
    " <div style=\"text-align:center\">\n",
    "    <img src=\"LSM table2.jpg\" width=\"600\">\n",
    "</div>\n",
    "  So, this will give us:\n",
    "\n",
    "  <div style=\"text-align:center\">\n",
    "    <img src=\"sum all.jpg\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "We can now start calculating m and b because they define the best-fitting line through the data points.\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"m b.jpg\" width=\"600\">\n",
    "</div>\n",
    "Therefore, the linear equation below represents the regression line that best fits the dataset.\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"y equation.jpg\" width=\"600\">\n",
    "</div> \n",
    "Now, let's check if the equation is valid. We check by plugging in x values 2 and 5 respectively, and then comparing the predicted y values with the actual values from the dataset.\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"LSM test.jpg\" width=\"600\">\n",
    "</div>\n",
    "As you can see here, predicted the y value of 2 is 3.99 which is not so far from the actual y value of 3.8. On the other hand, the predicted y value of 5 is 11.22, which is also near to the actual y value of 11.2.\n",
    "\n",
    "Despite the small difference in value, linear regression uses this method to predict potential outputs from the data given.\n",
    "\n",
    "Congrats, you now know how linear regression works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we have to understand how a linear regression model is evaluated.\n",
    "\n",
    "Linear regression model performances are evaluated by the Mean Square Error (MSE).\n",
    "\n",
    "<b>What is Mean Square Error (MSE)</b>\n",
    "\n",
    "A function that measures the amount of error in statistical models. It calculates the mean squared difference between the observed and predicted values.\n",
    "\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"MSE line.png\" width=\"600\">\n",
    "</div>\n",
    "As data points fall closer to the regression line, the model has less errors, deceasing the MSE.\n",
    "\n",
    "A lower MSE indicates that the model will produce precise predictions. Therefore, when the predicted values are closer to the actual values, the MSE will be smaller.\n",
    "</div>\n",
    "The Equation:\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"MSE.png\" width=\"600\">\n",
    "</div>\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"mse_2.jpg\" width=\"600\">\n",
    "</div>\n",
    "yi = the ith observed value\n",
    "\n",
    "\n",
    "\n",
    "yÌ‚i = the corresponding predicted value\n",
    "\n",
    "n = the number of observation\n",
    "\n",
    "Below is a simple MSE code.e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#data\n",
    "actual_values = np.array([2, 4, 6])\n",
    "predicted_values = np.array([1.5, 3.5, 5.5])\n",
    "\n",
    "#MSE\n",
    "mse = np.mean((actual_values - predicted_values) ** 2)\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 4 color='lightskyblue'>Code in action</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction:  [1.5 3.5 5.5]\n",
      "Error:  0.25\n"
     ]
    }
   ],
   "source": [
    "# Linear regression (Forward)\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "\n",
    "class LRFoward:\n",
    "    def get_model_prediction(self, X: NDArray[np.float64], weights: NDArray[np.float64]) -> NDArray[np.float64]:\n",
    "        prediction = np.matmul(X, weights)\n",
    "        return np.round(prediction, 5)\n",
    "    \n",
    "    def get_error(self, model_prediction: NDArray[np.float64], ground_truth: NDArray[np.float64]) -> float:\n",
    "        # for this MSE,  square it because its harder to derive an absolute function\n",
    "        error = np.mean(np.square(model_prediction - ground_truth))\n",
    "        return round(error, 5)\n",
    "\n",
    "# create instance for calling LR\n",
    "demo = LRFoward()\n",
    "\n",
    "# sample data\n",
    "X = np.array([[1, 2], [3, 4], [5, 6]], dtype=np.float64)  \n",
    "weights = np.array([0.5, 0.5], dtype=np.float64)          \n",
    "ground_truth = np.array([2, 4, 6], dtype=np.float64)    \n",
    "\n",
    "\n",
    "model_prediction = demo.get_model_prediction(X, weights)\n",
    "print(\"Model Prediction: \", model_prediction)\n",
    "\n",
    "\n",
    "error = demo.get_error(model_prediction, ground_truth)\n",
    "print(\"Error: \", error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='lightbrown'>Neural Networks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks is computational model built upon the principles of linear regression.\n",
    "\n",
    "Also known as Artificial Neural Networks (ANNs), these models are inspired by the structure of the human brain, imitating neurons and interconnected brain tissues by creating artificial neurons and interconnected nodes. This method is widely used in most modern machine learning models.\n",
    "\n",
    "Neural networks can be best represented like the graph below.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"neural_net.png\" width=\"300\">\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"nn_vis.png\" width=\"600\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>How does it work?</b>\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"nn_1.jpg\" width=\"500\">\n",
    "</div>\n",
    "\n",
    "The Input Layer is where we pass in x1, x2, and x3 as parameters (x-axis).\n",
    "\n",
    "The Hidden Layer are nodes that are connected to each node from the input layer and computes their data using linear regression. The catch is each node computes their own data parameters and are not related to other nodes in the hidden layer.\n",
    "\n",
    "More terms can be added to the linear regression equation if needed.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"nn_2.jpg\" width=\"500\">\n",
    "</div>\n",
    "\n",
    "The Output Layer are nodes connected to the nodes from the hidden layer, since we have 4 nodes in the hidden layer, the linear regression adds in a 5th term during computation. \n",
    "\n",
    "In the end, each node from the output layers is taken by the model and the average of that value is the final prediction.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these concepts in mind, we can  will use the pytorch library implement a neural network in code from scratch. \n",
    "\n",
    "To code out the nodes for different layers, we will use matrixes to implement them. These matrixes are called \"Tensors\" in the library.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 4 color='lightskyblue'>Code in action</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>\"Why are we using Pytorch?\"</i>\n",
    "\n",
    "Because Pytorch is specialized for creating neural networks, making it a more suitable material to learn from.\n",
    "\n",
    "Docs used: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cpu\n",
      "tensor([[0.2110]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# pip install torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "# build a neural network\n",
    "class NueralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # in features -> out features\n",
    "        self.first_layer = nn.Linear(3, 4)\n",
    "        # prev out features -> next out features\n",
    "        self.second_layer = nn.Linear(4,4)\n",
    "        # prev out layer -> final layer\n",
    "        self.final_layer = nn.Linear(4,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # passing data between layers\n",
    "        return self.final_layer(self.second_layer(self.first_layer(x)))\n",
    "\n",
    "# since weight is not defined, so it uses random numbers\n",
    "model = NueralNetwork()\n",
    "example_datapoint = torch.randn(1,3) # 1 by 3, it means 1 data point with 3 parameters\n",
    "\n",
    "print(model(example_datapoint))\n",
    "\n",
    "# note this mode is not trained, but it is a good example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our implemented neural network model visualized.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"nn_imp.jpg\" width=\"500\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='lightblue'>Gradient Descent</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent works in parallel with Linear Regression. Its objective is to <b><u>minimize the error</u></b> by updating the weights and biases of the model during training. \n",
    "\n",
    "** This process allows the model to \"learn\" from the training data by identifying the relationships within the data. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5 color='lightyellow'>How does it work?</font>\n",
    "\n",
    "Speaking in calculus terms, gradient descent is the process of finding the local minimum or global minimum of a differentiable function.\n",
    "\n",
    "In ML models, this calculus concept is transformed into an algorithm to help us find the parameter with the least errors to make a prediction.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"gd_2.jpg\" width=\"500\">\n",
    "</div>\n",
    "\n",
    "<b><u>Local minimum:</u></b>\n",
    "- A point where the function value is lower than at any nearby points, but there might be other points in the domain with even lower function values. So its deep but not the deepest one.\n",
    "\n",
    "<b><u>Global minimum:</u></b>\n",
    "- The absolute lowest point of the function over its entire domain (or graph). This is the point where the function value is the smallest compared to all other points, the deepest one we can find. \n",
    "\n",
    "\n",
    "<b>What do they mean?</b>\n",
    "\n",
    "The local minimum or global minimum represents the point where the machine learning model has the least amount of error in its predictions.\n",
    "\n",
    "To find these minima, we need to use derivatives from calculus.\n",
    "\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"gd_1.jpg\" width=\"500\">\n",
    "</div>\n",
    "\n",
    "As you can see, by using derivative properties, the global minimum is found within the domain of the function.\n",
    "\n",
    "This procedure is computed for each training data given to the model, finding the best possible prediction from each data points.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"gd_gen.jpg\" width=\"500\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5 color='lightgreen'>Show us the math!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <img src=\"eq_gd.jpg\" width=\"500\">\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"deri_1.jpg\" width=\"500\">\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"deri_2_2.jpg\" width=\"500\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 4 color='lightskyblue'>Code in action</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  0.0\n"
     ]
    }
   ],
   "source": [
    "# derivative for finding f(x) = x^2 only\n",
    "\n",
    "class derivative:\n",
    "    def get_minimizer(self, iterations:int, learning_rate: float, init: int) -> float: \n",
    "        minimizer = init\n",
    "\n",
    "        for i in range(iterations):\n",
    "            derivative = 2 * minimizer\n",
    "            minimizer = minimizer - learning_rate * derivative\n",
    "\n",
    "        return round(minimizer, 5)    \n",
    "    \n",
    "demo = derivative()\n",
    "\n",
    "iterations = 1000\n",
    "learning_rate = 0.1\n",
    "initial_value = 3\n",
    "\n",
    "minimizer = demo.get_minimizer(iterations, learning_rate, initial_value)\n",
    "print(\"x = \" ,minimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we can combine the concepts before and train a linear regression model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Weights: [-0.05547  0.11112  0.27771]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "class linearTraning:\n",
    "    def get_derivative(self, model_prediction: NDArray[np.float64], ground_truth: NDArray[np.float64], N: int, X: NDArray[np.float64], desired_weight: int) -> float:\n",
    "        return -2 * np.dot(ground_truth - model_prediction, X[:, desired_weight]) / N\n",
    "\n",
    "    def get_model_prediction(self, X: NDArray[np.float64], weights: NDArray[np.float64]) -> NDArray[np.float64]:\n",
    "        return np.squeeze(np.matmul(X, weights))\n",
    "\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    def train_model(\n",
    "        self, \n",
    "        X: NDArray[np.float64], \n",
    "        Y: NDArray[np.float64], \n",
    "        num_iterations: int, \n",
    "        initial_weights: NDArray[np.float64]\n",
    "    ) -> NDArray[np.float64]:\n",
    "        for _ in range(num_iterations):\n",
    "            model_prediction = self.get_model_prediction(X, initial_weights)\n",
    "\n",
    "            d1 = self.get_derivative(model_prediction, Y, len(X), X, 0)\n",
    "            d2 = self.get_derivative(model_prediction, Y, len(X), X, 1)\n",
    "            d3 = self.get_derivative(model_prediction, Y, len(X), X, 2)\n",
    "\n",
    "            initial_weights[0] = initial_weights[0] - d1 * self.learning_rate\n",
    "            initial_weights[1] = initial_weights[1] - d2 * self.learning_rate\n",
    "            initial_weights[2] = initial_weights[2] - d3 * self.learning_rate\n",
    "\n",
    "        return np.round(initial_weights, 5)\n",
    "\n",
    "demo = linearTraning()\n",
    "\n",
    "# 3 sample feature data in a matrix\n",
    "X = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "], dtype=np.float64)\n",
    "\n",
    "Y = np.array([1, 2, 3], dtype=np.float64)         \n",
    "initial_weights = np.array([0.1, 0.1, 0.1], dtype=np.float64)  # Initial weights for all 3\n",
    "\n",
    "# Train the model\n",
    "num_iterations = 1000\n",
    "trained_weights = demo.train_model(X, Y, num_iterations, initial_weights)\n",
    "print(\"Trained Weights:\", trained_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸŽ‰ Congratulations! Now you know how most Machine Learning model generate predictions with MATH!\n",
    "\n",
    "<b>However</b>, for real-world applications, the calculations can be more challenging and look something like the pictures below.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"gd_exm.png\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"gd_exm2.png\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "This type of gradient descent require us to get the direction of steepest increase using a greedy method. The formula given above will be the same but with an extra parameter to account for to get the direction.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
